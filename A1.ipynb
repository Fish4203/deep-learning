{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e2f6a-7351-4e21-b04a-dd3b7603de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e371a09-c507-4b57-9065-f4b12664c89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Monocyte', 'Neutrophil', 'Eosinophil', 'Basophil', 'Lymphocyte'}\n",
      "[1, 'round', 'unsegmented-band', 'no']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "allLabelDict = {}\n",
    "\n",
    "labelSet = set()\n",
    "with open(\"./dev_data_2025.csv\", \"r\") as f:\n",
    "\tcsvItems = list(csv.DictReader(f))\n",
    "\tfor imgLabel in csvItems:\n",
    "\t\tlabelSet.add(imgLabel['label'])\n",
    "\t\n",
    "\tlabelTuple = tuple(labelSet)\n",
    "\t\n",
    "\tfor imgLabel in csvItems:\n",
    "\t\tallLabelDict[imgLabel['imageID']] = [\n",
    "\t\t\tlabelTuple.index(imgLabel['label']), \n",
    "\t\t\timgLabel['cell_shape'], \n",
    "\t\t\timgLabel['nucleus_shape'], \n",
    "\t\t\timgLabel['cytoplasm_vacuole']\n",
    "\t\t]\n",
    "\n",
    "print(labelSet)\n",
    "print(allLabelDict['Img_00005'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90abb6e6-b570-4164-ad36-1d5377b99bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "10\n",
      "Image shape:  (100, 360, 360, 3)\n",
      "Label:  [1 3 1 4 3 2 2 1 1 1 1 3 2 2 3 3 1 1 4 1 4 1 2 1 1 1 0 0 1 1 0 4 2 3 0 3 4\n",
      " 0 2 0 1 4 4 2 2 2 3 2 2 2 2 3 2 1 2 0 0 2 4 1 2 1 2 0 2 1 1 1 2 2 2 0 1 1\n",
      " 1 1 3 2 1 2 1 2 0 1 1 1 2 0 2 1 1 3 1 1 2 1 3 2 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 00:12:54.193475: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "def getLabel(path):\n",
    "\tpath = path.numpy().decode(\"utf-8\")\n",
    "\tkey = os.path.basename(path)[:9]\n",
    "\t\n",
    "\tif key not in allLabelDict:\n",
    "\t\tprint(\"Missing key:\", key)\n",
    "\t\traise ValueError(\"Missing label key.\")\n",
    "\treturn allLabelDict[key]\n",
    "\n",
    "def getImage(path):\n",
    "\timg = tf.io.read_file(path)\n",
    "\timg = tf.io.decode_jpeg(img, channels=3)\n",
    "\treturn tf.image.resize_with_crop_or_pad(img, 360, 360)\n",
    "\n",
    "def process_path(file_path):    \n",
    "\tlabel = tf.py_function(func=getLabel, inp=[file_path], Tout=tf.uint32)\n",
    "\tlabel.set_shape([])\n",
    "\n",
    "\timg = tf.py_function(func=getImage, inp=[file_path], Tout=tf.uint8)\n",
    "\timg.set_shape([None, None, 3])\n",
    "\n",
    "\treturn img, label\n",
    "\n",
    "\n",
    "valSize = int(imageFileNames.cardinality().numpy() * 0.2)\n",
    "\n",
    "trainData = imageFileNames \\\n",
    "  .skip(valSize) \\\n",
    "  .map(process_path, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "  .cache() \\\n",
    "  .batch(100) \\\n",
    "  .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valData = imageFileNames \\\n",
    "  .take(valSize) \\\n",
    "  .map(process_path, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "  .cache() \\\n",
    "  .batch(100) \\\n",
    "  .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(tf.data.experimental.cardinality(trainData).numpy())\n",
    "print(tf.data.experimental.cardinality(valData).numpy())\n",
    "\n",
    "for image, label in trainData.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3f6ef77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 00:12:57.955565: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (100, 360, 360, 3) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, label \u001b[38;5;129;01min\u001b[39;00m trainData\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m      5\u001b[0m   ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m   \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;28mstr\u001b[39m(label\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m      8\u001b[0m   plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/deep/deep-learning/.venv/lib/python3.10/site-packages/matplotlib/pyplot.py:3601\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3579\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   3580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   3581\u001b[0m     X: ArrayLike \u001b[38;5;241m|\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3599\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3601\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3605\u001b[0m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3606\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3607\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3611\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3613\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3617\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3618\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3621\u001b[0m     sci(__ret)\n\u001b[1;32m   3622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/deep/deep-learning/.venv/lib/python3.10/site-packages/matplotlib/__init__.py:1524\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1530\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1531\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/deep/deep-learning/.venv/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5982\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5982\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5983\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5985\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/deep/deep-learning/.venv/lib/python3.10/site-packages/matplotlib/image.py:685\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    684\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/deep/deep-learning/.venv/lib/python3.10/site-packages/matplotlib/image.py:653\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    651\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    659\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (100, 360, 360, 3) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visuals\n",
    "plt.figure(figsize=(10, 10))\n",
    "i = 0\n",
    "for image, label in trainData.take(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "  plt.title(str(label.numpy()))\n",
    "  plt.axis(\"off\")\n",
    "  i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "deaea0bd-1ae2-41ce-9193-a9aef479fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/archfishgame/deep/deep-learning/.venv/lib/python3.10/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">358</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">358</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">179</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">179</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59168</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,893,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_6 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m360\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m358\u001b[0m, \u001b[38;5;34m358\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m179\u001b[0m, \u001b[38;5;34m179\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m177\u001b[0m, \u001b[38;5;34m177\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m88\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59168\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m1,893,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m165\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,914,021</span> (7.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,914,021\u001b[0m (7.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,914,021</span> (7.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,914,021\u001b[0m (7.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(labelSet)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255, input_shape=(360, 360, 3)),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "739d7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.3485 - loss: 1.4875 - val_accuracy: 0.4900 - val_loss: 1.2097\n",
      "Epoch 2/3\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 193ms/step - accuracy: 0.5680 - loss: 1.0393 - val_accuracy: 0.6600 - val_loss: 0.8742\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 00:14:49.092197: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 194ms/step - accuracy: 0.6902 - loss: 0.8055 - val_accuracy: 0.7100 - val_loss: 0.7549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 00:14:56.874720: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-08-14 00:14:57.059310: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  trainData,\n",
    "  validation_data=valData,\n",
    "  epochs=3,\n",
    "\tvalidation_steps=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04889f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
